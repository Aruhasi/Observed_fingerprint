{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b9370f-6718-47da-a1a5-862f7f35f1ca",
   "metadata": {},
   "source": [
    "### Calculation of the ratio S/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc7789-c98b-4eb3-bd53-7b6a80515a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "#In[2]:\n",
    "# define function\n",
    "import src.SAT_function as data_process\n",
    "import src.Data_Preprocess as preprosess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47083f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.slurm_cluster as scluster\n",
    "# client, scluster = scluster.init_dask_slurm_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e96fa",
   "metadata": {},
   "source": [
    "### Input both the forced and ICV_std trend data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0588375",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_forced= './Figure4_Regional_separation/reversed_trend_cal/data/'\n",
    "variable_name = np.arange(2013,1949,-1).astype(str)\n",
    "segment_lengths = np.arange(10, 74, 1).astype(str)\n",
    "\n",
    "# input into the dataset\n",
    "HadCRUT5_forced_ds = xr.Dataset()\n",
    "for var,segment_length in zip(variable_name,segment_lengths):\n",
    "    # print(var,segment_length)\n",
    "    file = dir_forced + 'forced_HadCRUT5_annual_'+var+'-2022_trend.nc'\n",
    "    ds = xr.open_mfdataset(file).rename({'__xarray_dataarray_variable__':'trend_forced'})\n",
    "    variable_name = f'forced_{segment_length}_trend'\n",
    "    HadCRUT5_forced_ds[variable_name] = ds['trend_forced']*10.0\n",
    "    \n",
    "print(HadCRUT5_forced_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fea96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT5_forced_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b166b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the standard deviation of SAT-OBS residuals\n",
    "dir_std = './Figure3/data/ICV_STD_whole/'\n",
    "\n",
    "HadCRUT5_ICV_std_ds = xr.Dataset()\n",
    "for segment_length in segment_lengths:\n",
    "    file = dir_std + 'GSAT_HadCRUT5_Internal_Variability_trend_'+segment_length+'yr_segments_1850_2022_std.nc'\n",
    "    ds = xr.open_mfdataset(file)\n",
    "    # print(ds)\n",
    "    variable_name = f'ICV_{segment_length}_std'\n",
    "    HadCRUT5_ICV_std_ds[variable_name] = ds[f'ICV_segments_{segment_length}yr_trend_std']\n",
    "    \n",
    "print(HadCRUT5_ICV_std_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT5_ICV_std_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361778be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate the ratio of the trend pattern of each segment to the standard deviation of the trend pattern of each interval of segments\n",
    "def SNR_trend_pattern(data, std_trend_pattern):\n",
    "    \"\"\"\n",
    "    data: 2D array with dimensions [lat, lon]\n",
    "    std_trend_pattern: 2D array with dimensions [lat, lon]\n",
    "    \"\"\"\n",
    "    return data/std_trend_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c5bdd-f1b9-4aee-8f3b-b886c6e472c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the trend pattern of each segment\n",
    "#       and calculate the ensemble standard deviation of the trend pattern of each interval of segments\n",
    "SNR_trend_pattern_ds = xr.Dataset()\n",
    "for segment_length in segment_lengths:\n",
    "    variable_name = f'SNR_{segment_length}_trend'\n",
    "    SNR_trend_pattern_ds[variable_name] = SNR_trend_pattern(HadCRUT5_forced_ds[f'forced_{segment_length}_trend'], HadCRUT5_ICV_std_ds[f'ICV_{segment_length}_std'])\n",
    "\n",
    "print(SNR_trend_pattern_ds[variable_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_trend_pattern_ds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result max and min\n",
    "for var in SNR_trend_pattern_ds.data_vars:\n",
    "    print(var)\n",
    "    print(SNR_trend_pattern_ds[var].max().values)\n",
    "    print(SNR_trend_pattern_ds[var].min().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the output \n",
    "# dir_out = './Figure3/data/Ratio/'\n",
    "\n",
    "# for segment_length in segment_lengths:\n",
    "#     file_out = dir_out + 'SNR_trend_pattern_HadCRUT5_'+segment_length+'yr_segments_ends_2022.nc'\n",
    "#     SNR_trend_pattern_ds[f'SNR_{segment_length}_trend'].to_netcdf(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b0183",
   "metadata": {},
   "source": [
    "### Plot the SNR ratio according to the trend length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 16\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['ytick.direction'] = 'out'\n",
    "plt.rcParams['ytick.minor.visible'] = True\n",
    "plt.rcParams['ytick.major.right'] = True\n",
    "plt.rcParams['ytick.right'] = True\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "# plt.rcParams['legend.frameon']      = False\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.mpl.ticker as cticker\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1f630",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. Stack the SNR values for each trend length: This will give each grid point a series of SNR values corresponding to different trend lengths.\n",
    "2. Find the first trend length where SNR >= 1.0: For each grid point, check the SNR values across all trend lengths and identify the first trend length where SNR exceeds or equals 1.0.\n",
    "3. Store the corresponding trend length: Create a 2D array (lat Ã— lon) where each grid point holds the first trend length that meets the SNR condition.\n",
    "4. Plot the results: Use contour shading to visualize the trend length where SNR first exceeds 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of trend lengths you're analyzing\n",
    "trend_lengths = np.arange(10, 74)\n",
    "\n",
    "# Stack the data into a new dimension for trend lengths\n",
    "stacked_snr = xr.concat([SNR_trend_pattern_ds[f'SNR_{t}_trend'] for t in trend_lengths], dim='trend_length')\n",
    "stacked_snr = stacked_snr.assign_coords(trend_length=trend_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stacked_snr.trend_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_valid_trend_length(snr_values):\n",
    "    \"\"\"\n",
    "    Find the first trend length where SNR > 1.0 and all subsequent SNR values are persistently > 1.0.\n",
    "    \n",
    "    Args:\n",
    "    - snr_values (np.ndarray): Array of SNR values for a specific grid point across all trend lengths.\n",
    "    \n",
    "    Returns:\n",
    "    - first_valid_idx (int or float): The index of the first trend length where SNR > 1.0 persistently,\n",
    "                                      or NaN if no such trend length is found.\n",
    "    \"\"\"\n",
    "    # Check where SNR > 1.0\n",
    "    condition = snr_values > 1.0\n",
    "\n",
    "    # Find the index of the first occurrence of SNR > 1.0\n",
    "    for idx in range(len(condition)):\n",
    "        # Check if SNR > 1.0 from this index onward is all True\n",
    "        if condition[idx] and np.all(condition[idx:]):\n",
    "            return idx  # Return the first valid index\n",
    "    \n",
    "    # If no valid index is found, return NaN\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_values = np.array([0.5, 0.8, 1.2, 1.5, 1.6])  # Example data\n",
    "result = first_valid_trend_length(snr_values)\n",
    "print(\"First valid trend length index:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find the first trend length where SNR >= 1.0\n",
    "first_trend_idx = xr.apply_ufunc(\n",
    "    first_valid_trend_length, \n",
    "    stacked_snr.chunk(dict(trend_length=-1)),  # Ensure the data is chunked along the trend_length dimension\n",
    "    input_core_dims=[['trend_length']],  # Apply function along each grid point\n",
    "    vectorize=True,                      # Apply in a vectorized way\n",
    "    dask='parallelized',                 # Enable parallel computation with Dask\n",
    "    output_dtypes=[float],               # Output will be float (since it may contain NaN)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert first_trend_idx to integers, but keep NaNs intact\n",
    "first_trend_idx_int = first_trend_idx.fillna(-1).astype(int)  # Replace NaNs with -1 temporarily\n",
    "\n",
    "# Step 2: Map indices to actual trend lengths\n",
    "first_trend_length_array = xr.DataArray(\n",
    "    np.where(first_trend_idx_int >= 0, trend_lengths[first_trend_idx_int], np.nan),  # Use trend lengths for valid indices, NaN for invalid\n",
    "    dims=['lat', 'lon'],  # Keep lat/lon dimensions\n",
    "    coords={'lat': first_trend_idx.lat, 'lon': first_trend_idx.lon}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5720e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(first_trend_length_array.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_trend_length_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_trend_length_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_trend_length_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each grid point across all trend lengths\n",
    "def is_monotonic_after_first(snr_values):\n",
    "    \"\"\"\n",
    "    Check if |S/N| values exceed 1.0 at some point and stay above 1.0 for all subsequent trend lengths.\n",
    "\n",
    "    Args:\n",
    "        snr_values (np.ndarray): Array of S/N values across trend lengths.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if from the first instance of |S/N| > 1.0 onwards, all values remain > 1.0.\n",
    "    \"\"\"\n",
    "    # Find the first index where |S/N| > 1.0\n",
    "    condition = np.abs(snr_values) > 1.0\n",
    "    first_valid_idx = np.argmax(condition) if np.any(condition) else None\n",
    "\n",
    "    if first_valid_idx is None:\n",
    "        # No S/N > 1.0, return False\n",
    "        return False\n",
    "\n",
    "    # Check if all subsequent values are also > 1.0\n",
    "    return np.all(np.abs(snr_values[first_valid_idx:]) > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic_map = xr.apply_ufunc(\n",
    "    is_monotonic_after_first,\n",
    "    stacked_snr.chunk(dict(trend_length=-1)),  # Ensure the data is chunked along the trend_length dimension\n",
    "    input_core_dims=[['trend_length']],  # Apply function along each grid point\n",
    "    vectorize=True,                      # Apply in a vectorized way\n",
    "    dask='parallelized',                 # Enable parallel computation with Dask\n",
    "    output_dtypes=[bool]  # Output is boolean (True/False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db511f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da35e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the monotonic test\n",
    "dir_out = './Revised_main_figures/Figure4_Emergence_timescale/data/'\n",
    "monotonic_map.to_dataset(name=\"monotonicity\").to_netcdf(dir_out+'obs_emergence_monotonicity.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7df5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trend(lons, lats, data, levels=None, extend=None, cmap=None, norm=None,\n",
    "                                 title=\"\", ax=None, show_xticks=False, show_yticks=False):\n",
    "    \"\"\"\n",
    "    Plot the trend spatial pattern using Robinson projection with significance overlaid.\n",
    "\n",
    "    Parameters:\n",
    "    - data: 2D numpy array with the trend values.\n",
    "    - lats, lons: 1D arrays of latitudes and longitudes.\n",
    "    - p_values: 2D array with p-values for each grid point.\n",
    "    - GMST_p_values: 2D array with GMST p-values for each grid point.\n",
    "    - title: Title for the plot.\n",
    "    - ax: Existing axis to plot on. If None, a new axis will be created.\n",
    "    - show_xticks, show_yticks: Boolean flags to show x and y axis ticks.\n",
    "    \n",
    "    Returns:\n",
    "    - contour_obj: The contour object from the plot.\n",
    "    \"\"\"\n",
    "# Create a new figure/axis if none is provided\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(20, 15), subplot_kw={'projection': ccrs.Robinson()})\n",
    "        ax.set_global()\n",
    "        \n",
    "    # contour_obj = ax.contourf(lons, lats, data, levels=levels, extend=extend, \n",
    "    #                         cmap=cmap, norm=norm, transform=ccrs.PlateCarree())\n",
    "    # Assuming lons, lats, data, levels, cmap, norm, and extend are already defined\n",
    "    pcolormesh_obj = ax.pcolormesh(lons, lats, data, norm=norm, cmap=cmap, shading='auto',\n",
    "                                   transform=ccrs.PlateCarree())\n",
    "    # pcolormesh_obj = data.plot.pcolormesh(ax=ax, transform=ccrs.PlateCarree(), cmap=cmap, norm=norm, \n",
    "    # add_colorbar=False)\n",
    "\n",
    "    # Plot significance masks with different hatches\n",
    "    # ax.contourf(lons, lats, significance_mask, levels=[0.05, 1.0],hatches=['///'], colors='none', transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.coastlines(resolution='110m')\n",
    "    gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, linewidth=1, linestyle='--',\n",
    "                      color='gray', alpha=0.35)\n",
    "\n",
    "    # Disable labels on the top and right of the plot\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Enable labels on the bottom and left of the plot\n",
    "    gl.bottom_labels = show_xticks\n",
    "    gl.left_labels = show_yticks\n",
    "    gl.xformatter = cticker.LongitudeFormatter()\n",
    "    gl.yformatter = cticker.LatitudeFormatter()\n",
    "    gl.xlabel_style = {'size': 16}\n",
    "    gl.ylabel_style = {'size': 16}\n",
    "    \n",
    "    if show_xticks:\n",
    "        gl.bottom_labels = True\n",
    "    if show_yticks:\n",
    "        gl.left_labels = True\n",
    "    \n",
    "    ax.set_title(title, loc='center', fontsize=24, pad=5.0)\n",
    "\n",
    "    return pcolormesh_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f71c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "nan_indices = np.isnan(first_trend_length_array)\n",
    "\n",
    "# Now you can print or analyze these points\n",
    "print(\"NaN indices:\", np.where(nan_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7849a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the boolean value True or False\n",
    "print(\"Monotonic map shape:\", monotonic_map.shape)\n",
    "# Check for True or False values\n",
    "true_indices = np.where(monotonic_map.values == True)\n",
    "# Now you can print or analyze these points\n",
    "print(\"True indices:\", true_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9df5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WH box (lat 42 to 60, lon 310 to 350)\n",
    "# wh_box = first_trend_length_array.sel(lat=slice(42, 60), lon=slice(310, 350))\n",
    "# print(\"WH Box First Trend Length Values:\\n\", wh_box.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so_box = first_trend_length_array.sel(lat=slice(-90, -42), lon=slice(180, 200))\n",
    "# print(\"SO Box First Trend Length Values:\\n\", so_box.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "import palettable\n",
    "import cartopy.util as cutil\n",
    "import numpy.ma as ma\n",
    "\n",
    "# cmdict = cmocean.cm.matter\n",
    "# norm = mcolors.Normalize(vmin=10, vmax=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trend_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first trend length where SNR >= 1.0\n",
    "fig, ax = plt.subplots(figsize=(15, 10), subplot_kw={'projection': ccrs.Robinson(180)})\n",
    "trend_lengths = np.append(np.arange(10, 75, 5), 75)  # [10, 15, ..., 75, 80]\n",
    "cmap_base = plt.get_cmap('OrRd_r')\n",
    "colors = cmap_base(np.linspace(0, 1, len(trend_lengths) - 1))  # One less than number of edges\n",
    "colors = np.vstack([colors, [1, 1, 1, 1]])  # Add white at the end for >75 years\n",
    "custom_cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm(trend_lengths, ncolors=len(trend_lengths) - 1)\n",
    "\n",
    "# trend_lengths = np.arange(10, 80, 5)  # Define the range of trend lengths\n",
    "# # Make a copy of the colormap before modifying it\n",
    "# cmap = copy.copy(plt.get_cmap('OrRd_r'))  # Use 'OrRd_r' reversed colormap\n",
    "\n",
    "# # Define BoundaryNorm for discrete colormap intervals\n",
    "# norm = BoundaryNorm(trend_lengths, cmap.N)  # cmap.N defines the number of colors in the colormap\n",
    "\n",
    "# extend = 'neither'  # No extension beyond the colormap range\n",
    "# cmdict_r = cmdict.reversed()\n",
    "\n",
    "# Mask invalid data (NaN or Inf values)\n",
    "masked_array = ma.masked_invalid(first_trend_length_array)\n",
    "\n",
    "# Add cyclic point to data and longitude\n",
    "Ratio_with_cyclic, lon_with_cyclic = cutil.add_cyclic_point(masked_array, coord=first_trend_length_array.lon)\n",
    "\n",
    "# Check the shapes to ensure consistency\n",
    "print(\"Shape of Ratio_with_cyclic:\", Ratio_with_cyclic.shape)\n",
    "print(\"Shape of lon_with_cyclic:\", lon_with_cyclic.shape)\n",
    "print(\"Shape of SNR_trend_pattern_ds.lat:\", SNR_trend_pattern_ds.lat.shape)\n",
    "\n",
    "# Plot the data (ensure 'contour' is the correct mappable object)\n",
    "pcolormesh_plot = plot_trend(lon_with_cyclic, SNR_trend_pattern_ds.lat, Ratio_with_cyclic,\n",
    "                                    levels=trend_lengths, extend='max', cmap=custom_cmap, norm=norm,\n",
    "                                        title='Emergence time scale (years)', ax=ax, show_xticks=True, show_yticks=True)\n",
    "# Assume monotonic_map is a boolean DataArray (True = monotonic, False = not monotonic)\n",
    "# and first_trend_length_array is your main data\n",
    "\n",
    "# Add cyclic point to monotonic_map for plotting\n",
    "monotonic_with_cyclic, lon_with_cyclic = cutil.add_cyclic_point(monotonic_map.values, coord=monotonic_map.lon)\n",
    "\n",
    "# Overlay the monotonicity mask as hatching (False = not monotonic)\n",
    "ax.contourf(\n",
    "    lon_with_cyclic, SNR_trend_pattern_ds.lat, ~monotonic_with_cyclic,\n",
    "    levels=[0.5, 1.5], hatches=['///'], colors='none', transform=ccrs.PlateCarree(), alpha=0\n",
    ")\n",
    "\n",
    "# Add the regional outlines and calculate midpoints for labels:\n",
    "# Arctic box\n",
    "arctic_lon_mid = (0 + 360) / 2\n",
    "arctic_lat_mid = (66.5 + 90) / 2\n",
    "ax.plot([0, 360, 360, 0, 0], [66.5, 66.5, 90, 90, 66.5],\n",
    "        color='lightgrey', linewidth=2.0, transform=ccrs.PlateCarree())\n",
    "ax.text(arctic_lon_mid, arctic_lat_mid, 'ARC', color='black', fontsize=18, transform=ccrs.PlateCarree(),\n",
    "        ha='center', va='center')  # Label for Arctic\n",
    "\n",
    "# WH box\n",
    "wh_lon_mid = (310 + 350) / 2\n",
    "wh_lat_mid = (42 + 60) / 2\n",
    "box_lons = np.array([310, 350, 350, 310, 310])\n",
    "box_lats = np.array([42, 42, 60, 60, 42])\n",
    "ax.plot(box_lons, box_lats, color='lightgrey', linewidth=2.0, transform=ccrs.PlateCarree())\n",
    "ax.text(wh_lon_mid, wh_lat_mid, 'NAWH', color='black', fontsize=18, transform=ccrs.PlateCarree(),\n",
    "        ha='center', va='center')  # Label for WH\n",
    "\n",
    "# Southeast Pacific box\n",
    "sep_lon_mid = (200 + 320) / 2\n",
    "sep_lat_mid = (0 + -25) / 2\n",
    "ax.plot([200%360, 280%360, 280%360, 250%360, 200%360], [0, 0, -25, -25, 0],\n",
    "        color='lightgrey', linewidth=2.0, transform=ccrs.PlateCarree())\n",
    "ax.text(sep_lon_mid, sep_lat_mid, 'SEP', color='black', fontsize=18, transform=ccrs.PlateCarree(),\n",
    "        ha='center', va='center')  # Label for SEP\n",
    "\n",
    "# Extratropical South Pacific box\n",
    "sop_lon_mid = (220 + 280) / 2\n",
    "sop_lat_mid = (-40 + -60) / 2\n",
    "ax.plot([220%360, 280%360, 280%360, 220%360, 220%360], [-40, -40, -60, -60, -40],\n",
    "        color='lightgrey', linewidth=2.0, transform=ccrs.PlateCarree())\n",
    "ax.text(sop_lon_mid, sop_lat_mid, 'SOP', color='black', fontsize=18, transform=ccrs.PlateCarree(),\n",
    "        ha='center', va='center')  # Label for SOP\n",
    "# Add colorbar for the plot\n",
    "\n",
    "cbar_ax = fig.add_axes([0.275, 0.12, 0.5, 0.04])\n",
    "cbar = plt.colorbar(pcolormesh_plot, cax=cbar_ax, orientation='horizontal', extend='max')\n",
    "# # Customize the colorbar\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "cbar.set_label('Emergence time scale (years)', fontsize=16)\n",
    "\n",
    "fig.savefig('Emergence_Trend_Length.png', dpi=300, bbox_inches='tight')\n",
    "fig.savefig('Emergence_Trend_Length.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e078b",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
