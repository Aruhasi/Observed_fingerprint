{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b9370f-6718-47da-a1a5-862f7f35f1ca",
   "metadata": {},
   "source": [
    "### Import the necessary database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc7789-c98b-4eb3-bd53-7b6a80515a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8116bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In[2]:\n",
    "# define function\n",
    "import src.SAT_function as data_process\n",
    "import src.Data_Preprocess as preprosess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c157868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.slurm_cluster as scluster\n",
    "# client, scluster = scluster.init_dask_slurm_cluster(scale=4, cores=40, memory=\"200GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_mk(x):\n",
    "    \"\"\"\n",
    "    Mann-Kendall test for trend\n",
    "    \"\"\"\n",
    "    results = data_process.apply_mannkendall(x)\n",
    "    slope = results[0]\n",
    "    p_val = results[1]\n",
    "    return slope, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0132846-56e9-4a2e-8fd3-02271dfb086b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input the MMEM of SAT-OBS internal variability\n",
    "dir_residuals = '/work/mh0033/m301036/Land_surf_temp/Disentangling_OBS_SAT_trend/Figure4/data/'\n",
    "ds_MME_HadCRUT5_1850_2022 = xr.open_mfdataset(dir_residuals + '1850_2022_Internal_arctic_mean.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_MME_HadCRUT5_1850_2022 = ds_MME_HadCRUT5_1850_2022.rename({'__xarray_dataarray_variable__': 'tas'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_MME_HadCRUT5_1850_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28f988-f36c-473d-abe9-86bac086e3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the running windows of the residuals of SAT-OBS\n",
    "#       with a series of equal length with an interval of 5 years starting from 10 years to 100 years\n",
    "#       and calculate the trend pattern of each segment\n",
    "#       and calculate the ensemble standard deviation of the trend pattern of each interval of segments\n",
    "\n",
    "# define the function to generate the running windows of the residuals of SAT-OBS\n",
    "def generate_segments(data, segment_length):\n",
    "    \"\"\"\n",
    "    data: 3D array with dimensions [year, lat, lon]\n",
    "    segment_length: length of each segment in years\n",
    "    \"\"\"\n",
    "    years = range(int(data['year'].min().item()), int(data['year'].max().item()) - segment_length + 2)\n",
    "    print(years)\n",
    "    # Initialize an empty list to store the segments\n",
    "    segments = []\n",
    "    \n",
    "    # For each year in the range\n",
    "    for year in years:\n",
    "        # Extract the segment of data from that year to year + segment_length\n",
    "        segment = data.sel(year=slice(str(year), str(year + segment_length - 1)))\n",
    "        \n",
    "        # Append this segment to the list of segments\n",
    "        segments.append(segment)\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e35584",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = np.arange(10, 74, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021615da",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56ac88-a9d9-49f7-b765-4660083b0068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the running windows of the residuals of SAT-OBS\n",
    "ICV_segments = {}\n",
    "for i in time_interval:\n",
    "    ICV_segments[i] = generate_segments(ds_MME_HadCRUT5_1850_2022['tas'], segment_length=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec97b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ICV_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_segments.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac337c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the trend values of each segment\n",
    "ICV_trend = {}\n",
    "for key in ICV_segments.keys():\n",
    "    print(key)\n",
    "    ICV_trend[key] = [data_process.mk_test(x)[0]*10.0 for x in ICV_segments[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22750e-d773-4fd6-a799-a534eece1065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Assuming ICV_segments is a dictionary with segment_length as keys and list of DataArray segments as values\n",
    "# max_num_segments = max(len(segments) for segments in ICV_segments.values())\n",
    "# segment_lengths = ICV_segments.keys()\n",
    "\n",
    "# # Create a new Dataset to hold the new arrays\n",
    "# new_ds = xr.Dataset()\n",
    "\n",
    "# for segment_length in segment_lengths:\n",
    "#     segments_list = ICV_segments[segment_length]\n",
    "#     # print(segments_list)\n",
    "    \n",
    "#     # Pad the segments list to have the same number of segments\n",
    "#     padded_segments = segments_list.copy()\n",
    "#     while len(padded_segments) < max_num_segments:\n",
    "#         # Create a DataArray filled with NaNs to match the shape of the segments\n",
    "#         nan_segment = xr.full_like(padded_segments[0], np.nan)\n",
    "#         padded_segments.append(nan_segment)\n",
    "    \n",
    "#     # Create a coordinate for the new segment dimension\n",
    "#     segment_coord = range(max_num_segments)\n",
    "    \n",
    "#     # Concatenate the padded segments with the new segment coordinate\n",
    "#     concatenated = xr.concat(padded_segments, dim=segment_coord)\n",
    "    \n",
    "#     # Assign a specific name to the new dimension\n",
    "#     concatenated = concatenated.rename({'concat_dim': 'segment'})\n",
    "    \n",
    "#     # Add the new DataArray to the new dataset\n",
    "#     new_ds[f'ICV_segments_{segment_length}yr'] = concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18796a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_combined = xr.merge([ds_MME_HadCRUT5_1850_2022, new_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dea401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13adaa4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the minimum and maximum of the new variable\n",
    "# ds_combined['ICV_segments_10yr'].min().values, ds_combined['ICV_segments_10yr'].max().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580cd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ICV_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_shapes(data_dict):\n",
    "    for key, value in data_dict.items():\n",
    "        if isinstance(value, list):\n",
    "            print(f\"{key}: List of {len(value)} elements\")\n",
    "            for i, item in enumerate(value):\n",
    "                shape = getattr(item, 'shape', 'No shape attribute')\n",
    "                print(f\"  Element {i}: {value}\")\n",
    "        else:\n",
    "            shape = getattr(value, 'shape', 'No shape attribute')\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_shapes(ICV_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4120fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ICV_trend[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ICV_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(len(segments) for segments in ICV_trend.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b0183",
   "metadata": {},
   "source": [
    "### Transform the dictionary to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd5929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ICV_segments is a dictionary with segment_length as keys and list of segments as values\n",
    "max_num_segments = max(len(segments) for segments in ICV_trend.values())\n",
    "segment_lengths = ICV_trend.keys()\n",
    "\n",
    "# Create a new Dataset to hold the new arrays\n",
    "new_ds = xr.Dataset()\n",
    "\n",
    "for segment_length in segment_lengths:\n",
    "    trend_list = ICV_trend[segment_length]\n",
    "    # print(trend_list)\n",
    "    \n",
    "    # Pad the trend list to have the same number of trend\n",
    "    padded_trend = trend_list.copy()\n",
    "    print(type(padded_trend))\n",
    "    # transform the list to DataArray\n",
    "    padded_trend = [xr.DataArray(x) for i, x in enumerate(padded_trend)]\n",
    "    while len(padded_trend) < max_num_segments:\n",
    "        # Create a DataArray filled with NaNs to match the shape of the trend\n",
    "        nan_segment = xr.full_like(padded_trend[0], np.nan)\n",
    "        padded_trend.append(nan_segment)\n",
    "    \n",
    "    # Create a coordinate for the new segment dimension\n",
    "    segment_coord = range(max_num_segments)\n",
    "    \n",
    "    # Concatenate the padded trend with the new segment coordinate\n",
    "    concatenated = xr.concat(padded_trend, dim=segment_coord)\n",
    "    \n",
    "    # Assign a specific name to the new dimension\n",
    "    concatenated = concatenated.rename({'concat_dim': 'segment'})\n",
    "    \n",
    "    # Add the new DataArray to the new dataset\n",
    "    new_ds[f'ICV_trend_{segment_length}yr'] = concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424613a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the trend pattern of each interval of segments\n",
    "\"\"\"\n",
    "drop the nan values in the trend pattern of each interval of segments\n",
    "\"\"\"\n",
    "# segements_10yr_trend = ds_combined['ICV_segments_10yr_trend'].dropna(dim='segment')\n",
    "# segements_11yr_trend = ds_combined['ICV_segments_11yr_trend'].dropna(dim='segment')\n",
    "# segements_12yr_trend = ds_combined['ICV_segments_12yr_trend'].dropna(dim='segment')\n",
    "# segements_13yr_trend = ds_combined['ICV_segments_13yr_trend'].dropna(dim='segment')\n",
    "# segements_14yr_trend = ds_combined['ICV_segments_14yr_trend'].dropna(dim='segment')\n",
    "# segements_15yr_trend = ds_combined['ICV_segments_15yr_trend'].dropna(dim='segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be149f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segements_15yr_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trend pattern of each segment\n",
    "dir_out = '/work/mh0033/m301036/Land_surf_temp/Disentangling_OBS_SAT_trend/Figure4/data/'\n",
    "new_ds.to_netcdf(dir_out + 'Internal_arctic_mean_trend_segmented.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e252a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Kernel",
   "language": "python",
   "name": "my-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
