{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b9370f-6718-47da-a1a5-862f7f35f1ca",
   "metadata": {},
   "source": [
    "### Calculation of the ratio S/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc7789-c98b-4eb3-bd53-7b6a80515a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "#In[2]:\n",
    "# define function\n",
    "import src.SAT_function as data_process\n",
    "import src.Data_Preprocess as preprosess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e96fa",
   "metadata": {},
   "source": [
    "### Input both the forced and ICV_std trend data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0588375",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in= '/work/mh0033/m301036/Land_surf_temp/Disentangling_OBS_SAT_trend/LE_evaluation/Fig3_IPSL/output/'\n",
    "\n",
    "IPSL_forced_ds = xr.open_mfdataset(dir_in + 'IPSL_forced_segmented_trend.nc').tas*10.0\n",
    "print(IPSL_forced_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad418afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming `ds` is your dataset\n",
    "# segment_lengths = range(10, 74, 1)  # Generate segment lengths from 10 to 73\n",
    "# new_period_names = [f\"forced_{length}yr_trend\" for length in segment_lengths]  # Create new names\n",
    "\n",
    "# # Replace the period coordinate\n",
    "# if len(new_period_names) == len(IPSL_forced_ds['tas'].period):\n",
    "#     IPSL_forced_ds['tas'] = IPSL_forced_ds['tas'].assign_coords(period=new_period_names)\n",
    "#     print(\"Updated period dimension successfully.\")\n",
    "# else:\n",
    "#     print(f\"Error: Mismatch in length. New names: {len(new_period_names)}, Current period: {len(IPSL_forced_ds['tas'].period)}\")\n",
    "\n",
    "# # Inspect the updated dataset\n",
    "# print(IPSL_forced_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPSL_forced_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input multiple runs ICV into one dataset with new variable dimension 'run'\n",
    "variable_indices = np.arange(1, 51, 1).astype(str)\n",
    "segment_lengths = np.arange(10, 74, 1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b166b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the standard deviation of SAT-OBS residuals\n",
    "dir_std = '/work/mh0033/m301036/Land_surf_temp/Disentangling_OBS_SAT_trend/LE_evaluation/Fig3_IPSL/output/'\n",
    "\n",
    "IPSL_ICV_std_ds = xr.open_mfdataset(dir_std + 'IPSL_ICV_noise_std_trend_pattern_1850_2022.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPSL_ICV_std_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bb008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the zero value in the std\n",
    "# std_trend_pattern = IPSL_ICV_std_ds['std_trend_10'].squeeze()\n",
    "# # Check where std_trend_pattern is zero\n",
    "# zero_mask = std_trend_pattern == 0\n",
    "\n",
    "# # Count the number of zeros\n",
    "# num_zeros = zero_mask.sum().item()\n",
    "# print(f\"Number of zeros in std_trend_pattern: {num_zeros}\")\n",
    "\n",
    "# # Optionally print locations (coordinates) of zero values\n",
    "# if num_zeros > 0:\n",
    "#     zero_coords = std_trend_pattern.where(zero_mask, drop=True)\n",
    "#     print(f\"Coordinates of zero values: {zero_coords}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361778be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate the ratio of the trend pattern of each segment to the standard deviation of the trend pattern of each interval of segments\n",
    "def SNR_trend_pattern(data, std_trend_pattern):\n",
    "    \"\"\"\n",
    "    data: 2D array with dimensions [lat, lon]\n",
    "    std_trend_pattern: 2D array with dimensions [lat, lon]\n",
    "    \"\"\"\n",
    "    safe_std = np.where(std_trend_pattern != 0,std_trend_pattern, 1e-10)\n",
    "    return data/safe_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90762669",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IPSL_forced_ds.sel(period=\"2013-2022\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c5bdd-f1b9-4aee-8f3b-b886c6e472c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the trend pattern of each segment and ensemble standard deviation\n",
    "num = np.arange(2013, 1949, -1)\n",
    "SNR_trend_pattern_ds = xr.Dataset()  # Use an xarray.Dataset to store results by key\n",
    "\n",
    "for segment_length, num in zip(segment_lengths, num):\n",
    "    # Construct the corresponding period key for the segment\n",
    "    forced_key = f\"{num}-2022\"\n",
    "    variable_name = f'SNR_{segment_length}_trend'\n",
    "    \n",
    "    # Debug: Print the selected forced trend period\n",
    "    print(f\"Processing segment length {segment_length}, forced key: {forced_key}\")\n",
    "    print(IPSL_forced_ds.sel(period=forced_key))\n",
    "    \n",
    "    # Apply the SNR trend pattern function\n",
    "    result = xr.apply_ufunc(\n",
    "        SNR_trend_pattern,\n",
    "        IPSL_forced_ds.sel(period=forced_key).chunk({\"run\": -1}),  # Adjust chunking\n",
    "        IPSL_ICV_std_ds[f'std_trend_{segment_length}'].chunk({\"run\": -1}),  # Adjust chunking\n",
    "        input_core_dims=[['lat', 'lon'], ['lat', 'lon']],  # Core dimensions\n",
    "        output_core_dims=[['lat', 'lon']],                # Output retains ['lat', 'lon']\n",
    "        vectorize=True,                                   # Vectorize across non-core dims\n",
    "        dask='parallelized',                              # Enable parallelization\n",
    "        output_dtypes=[float]                             # Output data type\n",
    "    )\n",
    "    \n",
    "    # Assign the result to the Dataset using the variable name\n",
    "    SNR_trend_pattern_ds[variable_name] = result\n",
    "\n",
    "# Final output\n",
    "print(SNR_trend_pattern_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_trend_pattern_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the output\n",
    "dir_out = '/work/mh0033/m301036/Land_surf_temp/Disentangling_OBS_SAT_trend/LE_evaluation/Fig3_IPSL/output/'\n",
    "SNR_trend_pattern_ds.to_netcdf(dir_out + 'IPSL_SNR_segments_pattern_1850_2022.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result max and min\n",
    "for var in SNR_trend_pattern_ds.data_vars:\n",
    "    print(var)\n",
    "    print(SNR_trend_pattern_ds[var].max().values)\n",
    "    print(SNR_trend_pattern_ds[var].min().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the output \n",
    "# dir_out = '/work/mh0033/m301036/Land_surf_temp/Disentangling_OBS_SAT_trend/Figure3/data/Ratio/'\n",
    "\n",
    "# for segment_length in segment_lengths:\n",
    "#     file_out = dir_out + 'SNR_trend_pattern_IPSL_'+segment_length+'yr_segments_ends_2022.nc'\n",
    "#     SNR_trend_pattern_ds[f'SNR_{segment_length}_trend'].to_netcdf(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b0183",
   "metadata": {},
   "source": [
    "### Plot the SNR ratio according to the trend length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 16\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['ytick.direction'] = 'out'\n",
    "plt.rcParams['ytick.minor.visible'] = True\n",
    "plt.rcParams['ytick.major.right'] = True\n",
    "plt.rcParams['ytick.right'] = True\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "# plt.rcParams['legend.frameon']      = False\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.mpl.ticker as cticker\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30faafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trend(trend_data, lats, lons, levels=None, extend=None, cmap=None, norm=None,\n",
    "                                 title=\"\", ax=None, show_xticks=False, show_yticks=False):\n",
    "    \"\"\"\n",
    "    Plot the trend spatial pattern using Robinson projection with significance overlaid.\n",
    "\n",
    "    Parameters:\n",
    "    - trend_data: 2D numpy array with the trend values.\n",
    "    - lats, lons: 1D arrays of latitudes and longitudes.\n",
    "    - p_values: 2D array with p-values for each grid point.\n",
    "    - GMST_p_values: 2D array with GMST p-values for each grid point.\n",
    "    - title: Title for the plot.\n",
    "    - ax: Existing axis to plot on. If None, a new axis will be created.\n",
    "    - show_xticks, show_yticks: Boolean flags to show x and y axis ticks.\n",
    "    \n",
    "    Returns:\n",
    "    - contour_obj: The contour object from the plot.\n",
    "    \"\"\"\n",
    "# Create a new figure/axis if none is provided\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(20, 15), subplot_kw={'projection': ccrs.Robinson()})\n",
    "        ax.set_global()\n",
    "        \n",
    "    contour_obj = ax.contourf(lons, lats, trend_data, levels=levels, extend=extend, cmap=cmap, norm=norm, transform=ccrs.PlateCarree(central_longitude=0))\n",
    "    # Plot significance masks with different hatches\n",
    "    # ax.contourf(lons, lats, significance_mask, levels=[0.05, 1.0],hatches=['///'], colors='none', transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.coastlines(resolution='110m')\n",
    "    gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, linewidth=1, linestyle='--',\n",
    "                      color='gray', alpha=0.35)\n",
    "\n",
    "    # Disable labels on the top and right of the plot\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Enable labels on the bottom and left of the plot\n",
    "    gl.bottom_labels = show_xticks\n",
    "    gl.left_labels = show_yticks\n",
    "    gl.xformatter = cticker.LongitudeFormatter()\n",
    "    gl.yformatter = cticker.LatitudeFormatter()\n",
    "    gl.xlabel_style = {'size': 16}\n",
    "    gl.ylabel_style = {'size': 16}\n",
    "    \n",
    "    if show_xticks:\n",
    "        gl.bottom_labels = True\n",
    "    if show_yticks:\n",
    "        gl.left_labels = True\n",
    "    \n",
    "    ax.set_title(title, loc='center', fontsize=18, pad=5.0)\n",
    "\n",
    "    return contour_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1f630",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. Stack the SNR values for each trend length: This will give each grid point a series of SNR values corresponding to different trend lengths.\n",
    "2. Find the first trend length where SNR >= 1.0: For each grid point, check the SNR values across all trend lengths and identify the first trend length where SNR exceeds or equals 1.0.\n",
    "3. Store the corresponding trend length: Create a 2D array (lat Ã— lon) where each grid point holds the first trend length that meets the SNR condition.\n",
    "4. Plot the results: Use contour shading to visualize the trend length where SNR first exceeds 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of trend lengths you're analyzing\n",
    "trend_lengths = np.arange(10, 74)\n",
    "\n",
    "# Stack the data into a new dimension for trend lengths\n",
    "stacked_snr = xr.concat([SNR_trend_pattern_ds[f'SNR_{t}_trend'] for t in trend_lengths], dim='trend_length')\n",
    "stacked_snr = stacked_snr.assign_coords(trend_length=trend_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27da092",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stacked_snr.trend_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to find the first occurrence of SNR >= 1.0\n",
    "# def first_valid_trend_length(snr_data):\n",
    "#     # Use np.argmax to find the first index where SNR >= 1.0\n",
    "#     condition = snr_data >= 1.0\n",
    "#     first_valid_idx = np.argmax(condition, axis=0)\n",
    "    \n",
    "#     # If no valid index is found, set to NaN (ignore if all are less than 1.0)\n",
    "#     no_valid = np.all(~condition, axis=0)\n",
    "#     first_valid_idx[no_valid] = np.nan\n",
    "    \n",
    "#     return first_valid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3171844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_valid_trend_length(snr_values):\n",
    "    \"\"\"\n",
    "    Find the first trend length where SNR >= 1.0.\n",
    "    \n",
    "    Args:\n",
    "    - snr_values (np.ndarray): Array of SNR values for a specific grid point across all trend lengths.\n",
    "    \n",
    "    Returns:\n",
    "    - first_valid_idx (np.ndarray or float): The index of the first trend length where SNR >= 1.0, \n",
    "                                             or NaN if no such trend length is found.\n",
    "    \"\"\"\n",
    "    # Mask negative SNR values by treating them as NaN\n",
    "    # snr_values = np.where(snr_values < 0, np.nan, snr_values)\n",
    "\n",
    "    # Check where SNR is >= 1.0\n",
    "    condition = abs(snr_values) > 1.0\n",
    "    \n",
    "    # Get the index of the first valid trend length where SNR >= 1.0\n",
    "    if np.any(condition):\n",
    "        first_valid_idx = np.argmax(condition, axis=0)\n",
    "    else:\n",
    "        first_valid_idx = np.nan  # Return NaN if no trend length satisfies the condition\n",
    "    \n",
    "    return first_valid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to find the first trend length where SNR >= 1.0\n",
    "first_trend_idx = xr.apply_ufunc(\n",
    "    first_valid_trend_length, \n",
    "    stacked_snr.chunk(dict(trend_length=-1),{\"run\": -1}),  # Ensure the data is chunked along the trend_length dimension\n",
    "    input_core_dims=[['trend_length']],  # Apply function along each grid point\n",
    "    vectorize=True,                      # Apply in a vectorized way\n",
    "    dask='parallelized',                 # Enable parallel computation with Dask\n",
    "    output_dtypes=[float],               # Output will be float (since it may contain NaN)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_trend_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert first_trend_idx to integers, but keep NaNs intact\n",
    "first_trend_idx_int = first_trend_idx.fillna(-1).astype(int)  # Replace NaNs with -1 temporarily\n",
    "\n",
    "# Step 2: Map indices to actual trend lengths\n",
    "first_trend_length_array = xr.DataArray(\n",
    "    np.where(first_trend_idx_int >= 0, trend_lengths[first_trend_idx_int], np.nan),  # Use trend lengths for valid indices, NaN for invalid\n",
    "    dims=['run','lat', 'lon'],  # Keep lat/lon dimensions\n",
    "    coords={'run': first_trend_idx.run,'lat': first_trend_idx.lat, 'lon': first_trend_idx.lon}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5720e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(first_trend_length_array.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_trend_length_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_trend_length_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_trend_length_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00351b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the emergence data \n",
    "dir_out = '/work/mh0033/m301036/Land_surf_temp/Disentangling_OBS_SAT_trend/LE_evaluation/Fig3_IPSL/output/'\n",
    "first_trend_length_array.to_netcdf(dir_out + 'IPSL_emergence_timescale.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the ensemble mean of the first valid trend length in run dimension\n",
    "\n",
    "first_trend_length_array_mean = first_trend_length_array.mean(dim='run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7df5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trend(lons, lats, data, levels=None, extend=None, cmap=None, norm=None,\n",
    "                                 title=\"\", ax=None, show_xticks=False, show_yticks=False):\n",
    "    \"\"\"\n",
    "    Plot the trend spatial pattern using Robinson projection with significance overlaid.\n",
    "\n",
    "    Parameters:\n",
    "    - data: 2D numpy array with the trend values.\n",
    "    - lats, lons: 1D arrays of latitudes and longitudes.\n",
    "    - p_values: 2D array with p-values for each grid point.\n",
    "    - GMST_p_values: 2D array with GMST p-values for each grid point.\n",
    "    - title: Title for the plot.\n",
    "    - ax: Existing axis to plot on. If None, a new axis will be created.\n",
    "    - show_xticks, show_yticks: Boolean flags to show x and y axis ticks.\n",
    "    \n",
    "    Returns:\n",
    "    - contour_obj: The contour object from the plot.\n",
    "    \"\"\"\n",
    "# Create a new figure/axis if none is provided\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(20, 15), subplot_kw={'projection': ccrs.Robinson()})\n",
    "        ax.set_global()\n",
    "        \n",
    "    # contour_obj = ax.contourf(lons, lats, data, levels=levels, extend=extend, \n",
    "    #                         cmap=cmap, norm=norm, transform=ccrs.PlateCarree())\n",
    "    # Assuming lons, lats, data, levels, cmap, norm, and extend are already defined\n",
    "    pcolormesh_obj = ax.pcolormesh(lons, lats, data, norm=norm, cmap=cmap, shading='auto',\n",
    "                                   transform=ccrs.PlateCarree())\n",
    "    # pcolormesh_obj = data.plot.pcolormesh(ax=ax, transform=ccrs.PlateCarree(), cmap=cmap, norm=norm, \n",
    "    # add_colorbar=False)\n",
    "\n",
    "    # Plot significance masks with different hatches\n",
    "    # ax.contourf(lons, lats, significance_mask, levels=[0.05, 1.0],hatches=['///'], colors='none', transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.coastlines(resolution='110m')\n",
    "    gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, linewidth=1, linestyle='--',\n",
    "                      color='gray', alpha=0.35)\n",
    "\n",
    "    # Disable labels on the top and right of the plot\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Enable labels on the bottom and left of the plot\n",
    "    gl.bottom_labels = show_xticks\n",
    "    gl.left_labels = show_yticks\n",
    "    gl.xformatter = cticker.LongitudeFormatter()\n",
    "    gl.yformatter = cticker.LatitudeFormatter()\n",
    "    gl.xlabel_style = {'size': 16}\n",
    "    gl.ylabel_style = {'size': 16}\n",
    "    \n",
    "    if show_xticks:\n",
    "        gl.bottom_labels = True\n",
    "    if show_yticks:\n",
    "        gl.left_labels = True\n",
    "    \n",
    "    ax.set_title(title, loc='center', fontsize=24, pad=5.0)\n",
    "\n",
    "    return pcolormesh_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d90028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the emergence time scale of ensemble mean\n",
    "dir_out = '/work/mh0033/m301036/Land_surf_temp/Disentangling_OBS_SAT_trend/LE_evaluation/Fig3_IPSL/output/'\n",
    "first_trend_length_array_mean.to_netcdf(dir_out + 'IPSL_emergence_timescale_mean.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6704d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "import palettable\n",
    "import cartopy.util as cutil\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first trend length where SNR >= 1.0\n",
    "fig, ax = plt.subplots(figsize=(15, 10), subplot_kw={'projection': ccrs.Robinson(180)})\n",
    "\n",
    "trend_lengths = np.arange(10, 80, 5)  # Define the range of trend lengths\n",
    "# Make a copy of the colormap before modifying it\n",
    "cmap = plt.get_cmap(\"Spectral\") #copy.copy(plt.get_cmap('OrRd_r'))  # Use 'OrRd_r' reversed colormap\n",
    "# Define BoundaryNorm for discrete colormap intervals\n",
    "norm = BoundaryNorm(trend_lengths, cmap.N)  # cmap.N defines the number of colors in the colormap\n",
    "\n",
    "extend = 'neither'  # No extension beyond the colormap range\n",
    "# cmdict_r = cmdict.reversed()\n",
    "\n",
    "data_plot = first_trend_length_array_mean.values\n",
    "# Mask invalid data (NaN or Inf values)\n",
    "masked_array = ma.masked_invalid(data_plot)\n",
    "\n",
    "# Add cyclic point to data and longitude\n",
    "Ratio_with_cyclic, lon_with_cyclic = cutil.add_cyclic_point(masked_array, coord=first_trend_length_array.lon)\n",
    "\n",
    "# Check the shapes to ensure consistency\n",
    "print(\"Shape of Ratio_with_cyclic:\", Ratio_with_cyclic.shape)\n",
    "print(\"Shape of lon_with_cyclic:\", lon_with_cyclic.shape)\n",
    "print(\"Shape of SNR_trend_pattern_ds.lat:\", SNR_trend_pattern_ds.lat.shape)\n",
    "\n",
    "# Plot the data (ensure 'contour' is the correct mappable object)\n",
    "pcolormesh_plot = plot_trend(lon_with_cyclic, SNR_trend_pattern_ds.lat, Ratio_with_cyclic,\n",
    "                                    levels=trend_lengths, extend=extend, cmap=cmap, norm=norm,\n",
    "                                        title='Emergence time scale (years)', ax=ax, show_xticks=True, show_yticks=True)\n",
    "\n",
    "\n",
    "# Add the regional outlines and calculate midpoints for labels:\n",
    "# Arctic box\n",
    "arctic_lon_mid = (0 + 360) / 2\n",
    "arctic_lat_mid = (66.5 + 90) / 2\n",
    "ax.plot([0, 360, 360, 0, 0], [66.5, 66.5, 90, 90, 66.5],\n",
    "        color='lightgrey', linewidth=2.0, transform=ccrs.PlateCarree())\n",
    "ax.text(arctic_lon_mid, arctic_lat_mid, 'ARC', color='black', fontsize=18, transform=ccrs.PlateCarree(),\n",
    "        ha='center', va='center')  # Label for Arctic\n",
    "\n",
    "# WH box\n",
    "wh_lon_mid = (310 + 350) / 2\n",
    "wh_lat_mid = (42 + 60) / 2\n",
    "box_lons = np.array([310, 350, 350, 310, 310])\n",
    "box_lats = np.array([42, 42, 60, 60, 42])\n",
    "ax.plot(box_lons, box_lats, color='lightgrey', linewidth=2.0, transform=ccrs.PlateCarree())\n",
    "ax.text(wh_lon_mid, wh_lat_mid, 'NAWH', color='black', fontsize=18, transform=ccrs.PlateCarree(),\n",
    "        ha='center', va='center')  # Label for WH\n",
    "\n",
    "# Southeast Pacific box\n",
    "sep_lon_mid = (200 + 320) / 2\n",
    "sep_lat_mid = (0 + -25) / 2\n",
    "ax.plot([200%360, 280%360, 280%360, 250%360, 200%360], [0, 0, -25, -25, 0],\n",
    "        color='lightgrey', linewidth=2.0, transform=ccrs.PlateCarree())\n",
    "ax.text(sep_lon_mid, sep_lat_mid, 'SEP', color='black', fontsize=18, transform=ccrs.PlateCarree(),\n",
    "        ha='center', va='center')  # Label for SEP\n",
    "\n",
    "# Extratropical South Pacific box\n",
    "sop_lon_mid = (220 + 280) / 2\n",
    "sop_lat_mid = (-40 + -60) / 2\n",
    "ax.plot([220%360, 280%360, 280%360, 220%360, 220%360], [-40, -40, -60, -60, -40],\n",
    "        color='lightgrey', linewidth=2.0, transform=ccrs.PlateCarree())\n",
    "ax.text(sop_lon_mid, sop_lat_mid, 'SOP', color='black', fontsize=18, transform=ccrs.PlateCarree(),\n",
    "        ha='center', va='center')  # Label for SOP\n",
    "# Add colorbar for the plot\n",
    "\n",
    "cbar_ax = fig.add_axes([0.275, 0.12, 0.5, 0.04])\n",
    "cbar = plt.colorbar(pcolormesh_plot, cax=cbar_ax, orientation='horizontal')\n",
    "# # Customize the colorbar\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "cbar.set_label('Emergence time scale (years)', fontsize=16)\n",
    "\n",
    "fig.savefig('Emergence_Trend_Length.png', dpi=300, bbox_inches='tight')\n",
    "fig.savefig('Emergence_Trend_Length.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb423304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd1e078b",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
