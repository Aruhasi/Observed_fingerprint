{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional SAT anomalies calculation then calculate the trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "# %%\n",
    "# define function\n",
    "import src.SAT_function as data_process\n",
    "import src.Data_Preprocess as preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.slurm_cluster as scluster\n",
    "# client, scluster = scluster.init_dask_slurm_cluster(scale=2,cores=10, memory=\"200GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_mk(x):\n",
    "    \"\"\"\n",
    "    Mann-Kendall test for trend\n",
    "    \"\"\"\n",
    "    results = data_process.mk_test(x)\n",
    "    slope = results[0]\n",
    "    p_val = results[1]\n",
    "    return slope, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dir_HadCRUT5 = './Figure1/'\n",
    "HadCRUT5 = xr.open_dataset(dir_HadCRUT5 + 'tas_HadCRUT5_annual_anomalies_processed.nc')\n",
    "\n",
    "dir1 = './Supplementary/S1/data_revise/'\n",
    "HadCRUT5_forced = xr.open_mfdataset(dir1 + 'HadCRUT_Forced_signal.nc',chunks={'lat':10,'lon':10})\n",
    "HadCRUT5_internal = xr.open_mfdataset(dir1 + 'HadCRUT_residual.nc',chunks={'lat':10,'lon':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT5 = HadCRUT5.rename({'__xarray_dataarray_variable__':'tas'})\n",
    "HadCRUT5_forced = HadCRUT5_forced.rename({'__xarray_dataarray_variable__':'tas'})\n",
    "HadCRUT5_internal = HadCRUT5_internal.rename({'__xarray_dataarray_variable__':'tas'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the trend end year fix to 2022, start with 73 year length and decrease length of trend every one year, the minimum trend length is 10yr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = HadCRUT5.tas\n",
    "temp_data_forced = HadCRUT5_forced.tas\n",
    "temp_data_internal = HadCRUT5_internal.tas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regional anomalies calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trend(temp_data, lats, lons, levels=None, extend=None, cmap=None, \n",
    "                                 title=\"\", ax=None, show_xticks=False, show_yticks=False):\n",
    "    \"\"\"\n",
    "    Plot the trend spatial pattern using Robinson projection with significance overlaid.\n",
    "\n",
    "    Parameters:\n",
    "    - temp_data: 2D numpy array with the trend values.\n",
    "    - lats, lons: 1D arrays of latitudes and longitudes.\n",
    "    - p_values: 2D array with p-values for each grid point.\n",
    "    - GMST_p_values: 2D array with GMST p-values for each grid point.\n",
    "    - title: Title for the plot.\n",
    "    - ax: Existing axis to plot on. If None, a new axis will be created.\n",
    "    - show_xticks, show_yticks: Boolean flags to show x and y axis ticks.\n",
    "    \n",
    "    Returns:\n",
    "    - contour_obj: The contour object from the plot.\n",
    "    \"\"\"\n",
    "    # Plotting\n",
    "    contour_obj = ax.contourf(lons, lats, temp_data, levels=levels, extend=extend, cmap=cmap, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.coastlines(resolution='110m')\n",
    "    gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False,\n",
    "                      color='gray', alpha=0.35, linestyle='--')\n",
    "\n",
    "    # Disable labels on the top and right of the plot\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Enable labels on the bottom and left of the plot\n",
    "    gl.bottom_labels = show_xticks\n",
    "    gl.left_labels = show_yticks\n",
    "    gl.xformatter = cticker.LongitudeFormatter()\n",
    "    gl.yformatter = cticker.LatitudeFormatter()\n",
    "    gl.xlabel_style = {'size': 16}\n",
    "    gl.ylabel_style = {'size': 16}\n",
    "    \n",
    "    if show_xticks:\n",
    "        gl.bottom_labels = True\n",
    "    if show_yticks:\n",
    "        gl.left_labels = True\n",
    "    \n",
    "    # ax.set_title(title, loc='center', fontsize=18, pad=5.0)\n",
    "\n",
    "    return contour_obj\n",
    "# %%\n",
    "plt.rcParams['figure.figsize'] = (8, 10)\n",
    "plt.rcParams['font.size'] = 16\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['ytick.direction'] = 'out'\n",
    "plt.rcParams['ytick.minor.visible'] = True\n",
    "plt.rcParams['ytick.major.right'] = True\n",
    "plt.rcParams['ytick.right'] = True\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "plt.rcParams['savefig.pad_inches'] = 0.1\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.mpl.ticker as cticker\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "import cartopy.util as cutil\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = temp_data.lat\n",
    "lon = temp_data.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extratropical South Pacific region\n",
    "lat1 = -70\n",
    "lat2 = -55\n",
    "lon1 = 180\n",
    "lon2 = 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_SOP,lons_SOP, lats_SOP = data_process.selreg(\n",
    "        temp_data, lat, lon, lat1=lat1, lat2=lat2, lon1=lon1, \n",
    "        lon2=lon2)\n",
    "temp_forced_da_SOP,lons_SOP, lats_SOP = data_process.selreg(\n",
    "        temp_data_forced, lat, lon, lat1=lat1, lat2=lat2, lon1=lon1, \n",
    "        lon2=lon2)\n",
    "\n",
    "temp_internal_da_SOP,lons_SOP, lats_SOP = data_process.selreg(\n",
    "        temp_data_internal, lat, lon, lat1=lat1, lat2=lat2, lon1=lon1, \n",
    "        lon2=lon2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_forced_da_SOP_mean = data_process.calc_weighted_mean(temp_forced_da_SOP)\n",
    "temp_internal_da_SOP_mean = data_process.calc_weighted_mean(temp_internal_da_SOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the SOP region SAT anomalies\n",
    "temp_da_SOP_mean = data_process.calc_weighted_mean(temp_data_SOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_da_SOP_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out = './Figure5/check_SO_region/data/'\n",
    "\n",
    "# temp_da_SOP_mean.to_netcdf(dir_out + '1850_2022_Raw_SOP_mean.nc')\n",
    "# temp_forced_da_SOP_mean.to_netcdf(dir_out + '1850_2022_Forced_SOP_mean.nc')\n",
    "# temp_internal_da_SOP_mean.to_netcdf(dir_out + '1850_2022_Internal_SOP_mean.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segments definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "start_year = 1950\n",
    "end_year = 2022\n",
    "min_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(start_year, end_year + 1)\n",
    "\n",
    "# Prepare a dictionary to hold the trend DataArrays for each period\n",
    "temp_data_segments = {}\n",
    "\n",
    "for begin_year in range(start_year, end_year - min_length+2):\n",
    "    # Select the data from the start year to the last year\n",
    "    time_slice = temp_da_SOP_mean.sel(year=slice(begin_year, end_year))\n",
    "    \n",
    "    temp_data_segments[begin_year] = time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_forced_segments = {}\n",
    "temp_data_internal_segments = {}\n",
    "\n",
    "for begin_year in range(start_year, end_year - min_length+2):\n",
    "    # Select the data from the start year to the last year\n",
    "    time_slice = temp_forced_da_SOP_mean.sel(year=slice(begin_year, end_year))\n",
    "    \n",
    "    temp_data_forced_segments[begin_year] = time_slice\n",
    "\n",
    "for begin_year in range(start_year, end_year - min_length+2):\n",
    "    # Select the data from the start year to the last year\n",
    "    time_slice = temp_internal_da_SOP_mean.sel(year=slice(begin_year, end_year))\n",
    "    \n",
    "    temp_data_internal_segments[begin_year] = time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_data_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_data_segments.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the trend for each segment\n",
    "trends = {}\n",
    "\n",
    "for begin_year in temp_data_segments.keys():\n",
    "    temp_data = temp_data_segments[begin_year]\n",
    "    temp_data_forced = temp_data_forced_segments[begin_year]\n",
    "    temp_data_internal = temp_data_internal_segments[begin_year]\n",
    "    \n",
    "    # Calculate the trend for each segment\n",
    "    trends[begin_year] = {}\n",
    "    trends[begin_year]['raw'] = data_process.mk_test(temp_data,a=0.05)[0]*10.0\n",
    "    trends[begin_year]['forced'] = data_process.mk_test(temp_data_forced,a=0.05)[0]*10.0\n",
    "    trends[begin_year]['internal'] = data_process.mk_test(temp_data_internal,a=0.05)[0]*10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dictionary to dataframe\n",
    "trends_df = pd.DataFrame(trends).T\n",
    "trends_df\n",
    "\n",
    "# for interval, data in temp_annual_np.items():\n",
    "#     temp_annual_da[interval] = xr.DataArray(data, dims=[\"lat\", \"lon\"], coords={\"lat\": temp_data[interval].lat, \"lon\": temp_data[interval].lon})\n",
    "# for interval, data in pvalue_annual_np.items():\n",
    "#     pvalue_annual_da[interval] = xr.DataArray(data, dims=[\"lat\", \"lon\"], coords={\"lat\": temp_data[interval].lat, \"lon\": temp_data[interval].lon})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame to dataset\n",
    "trends_ds = trends_df.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export the trend to the netcdf file\n",
    "# trends_ds.to_netcdf(dir_out + 'SOP_trend_variations.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirin = './Figure5/check_SO_region/data/'\n",
    "SOP_unforced_lower = xr.open_dataset(f'{dirin}internal_SOP_trend_lower_percentile.nc')\n",
    "SOP_unforced_upper = xr.open_dataset(f'{dirin}internal_SOP_trend_upper_percentile.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOP_unforced_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOP_unforced_lower = SOP_unforced_lower.rename_vars({'__xarray_dataarray_variable__':'trend'})\n",
    "SOP_unforced_upper = SOP_unforced_upper.rename_vars({'__xarray_dataarray_variable__':'trend'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOP_unforced_lower"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
