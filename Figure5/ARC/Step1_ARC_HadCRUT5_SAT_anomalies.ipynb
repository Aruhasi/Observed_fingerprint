{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional SAT anomalies calculation then calculate the trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "# %%\n",
    "# define function\n",
    "import src.SAT_function as data_process\n",
    "import src.Data_Preprocess as preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.slurm_cluster as scluster\n",
    "# client, scluster = scluster.init_dask_slurm_cluster(scale=2,cores=10, memory=\"200GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_mk(x):\n",
    "    \"\"\"\n",
    "    Mann-Kendall test for trend\n",
    "    \"\"\"\n",
    "    results = data_process.mk_test(x)\n",
    "    slope = results[0]\n",
    "    p_val = results[1]\n",
    "    return slope, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dir_HadCRUT5 = './Figure1/'\n",
    "HadCRUT5 = xr.open_dataset(dir_HadCRUT5 + 'tas_HadCRUT5_annual_anomalies_processed.nc')\n",
    "\n",
    "dir1 ='./Supplementary/S1/data_revise/'\n",
    "HadCRUT5_forced = xr.open_mfdataset(dir1 + 'HadCRUT_Forced_signal.nc',chunks={'lat':10,'lon':10})\n",
    "HadCRUT5_internal = xr.open_mfdataset(dir1 + 'HadCRUT_residual.nc',chunks={'lat':10,'lon':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadCRUT5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the trend end year fix to 2022, start with 73 year length and decrease length of trend every one year, the minimum trend length is 10yr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = HadCRUT5.tas\n",
    "temp_data_forced = HadCRUT5_forced.tas\n",
    "temp_data_internal = HadCRUT5_internal.tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip the longitude to -180 to 180\n",
    "temp_data_adj = preprocess.adjust_longitude(temp_data, temp_data.lon)\n",
    "temp_data_forced_adj = preprocess.adjust_longitude(temp_data_forced, temp_data_forced.lon)\n",
    "temp_data_internal_adj = preprocess.adjust_longitude(temp_data_internal, temp_data_internal.lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array to xarray\n",
    "temp_da = xr.DataArray(temp_data_adj[0], coords=[temp_data.year, temp_data.lat, temp_data_adj[1]], dims=['year', 'lat', 'lon'])\n",
    "temp_forced_da = xr.DataArray(temp_data_forced_adj[0], coords=[temp_data_forced.year, temp_data_forced.lat, temp_data_forced_adj[1]], dims=['year', 'lat', 'lon'])\n",
    "temp_internal_da = xr.DataArray(temp_data_internal_adj[0], coords=[temp_data_internal.year, temp_data_internal.lat, temp_data_internal_adj[1]], dims=['year', 'lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_forced_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regional anomalies calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trend(temp_data, lats, lons, levels=None, extend=None, cmap=None, \n",
    "                                 title=\"\", ax=None, show_xticks=False, show_yticks=False):\n",
    "    \"\"\"\n",
    "    Plot the trend spatial pattern using Robinson projection with significance overlaid.\n",
    "\n",
    "    Parameters:\n",
    "    - temp_data: 2D numpy array with the trend values.\n",
    "    - lats, lons: 1D arrays of latitudes and longitudes.\n",
    "    - p_values: 2D array with p-values for each grid point.\n",
    "    - GMST_p_values: 2D array with GMST p-values for each grid point.\n",
    "    - title: Title for the plot.\n",
    "    - ax: Existing axis to plot on. If None, a new axis will be created.\n",
    "    - show_xticks, show_yticks: Boolean flags to show x and y axis ticks.\n",
    "    \n",
    "    Returns:\n",
    "    - contour_obj: The contour object from the plot.\n",
    "    \"\"\"\n",
    "    # Plotting\n",
    "    contour_obj = ax.contourf(lons, lats, temp_data, levels=levels, extend=extend, cmap=cmap, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.coastlines(resolution='110m')\n",
    "    gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False,\n",
    "                      color='gray', alpha=0.35, linestyle='--')\n",
    "\n",
    "    # Disable labels on the top and right of the plot\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "\n",
    "    # Enable labels on the bottom and left of the plot\n",
    "    gl.bottom_labels = show_xticks\n",
    "    gl.left_labels = show_yticks\n",
    "    gl.xformatter = cticker.LongitudeFormatter()\n",
    "    gl.yformatter = cticker.LatitudeFormatter()\n",
    "    gl.xlabel_style = {'size': 16}\n",
    "    gl.ylabel_style = {'size': 16}\n",
    "    \n",
    "    if show_xticks:\n",
    "        gl.bottom_labels = True\n",
    "    if show_yticks:\n",
    "        gl.left_labels = True\n",
    "    \n",
    "    # ax.set_title(title, loc='center', fontsize=18, pad=5.0)\n",
    "\n",
    "    return contour_obj\n",
    "# %%\n",
    "plt.rcParams['figure.figsize'] = (8, 10)\n",
    "plt.rcParams['font.size'] = 16\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['ytick.direction'] = 'out'\n",
    "plt.rcParams['ytick.minor.visible'] = True\n",
    "plt.rcParams['ytick.major.right'] = True\n",
    "plt.rcParams['ytick.right'] = True\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "plt.rcParams['savefig.pad_inches'] = 0.1\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.mpl.ticker as cticker\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "import cartopy.util as cutil\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = temp_da.lat\n",
    "lon = temp_da.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arctic region \n",
    "lat1 = 66.5\n",
    "lat2 = 90\n",
    "lon1 = -180\n",
    "lon2 = 180\n",
    "# select the region\n",
    "\n",
    "temp_da_arctic,lons_Arctic, lats_Arctic = data_process.selreg(\n",
    "        temp_da, lat, lon, lat1=lat1, lat2=lat2, lon1=lon1, \n",
    "        lon2=lon2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_da_arctic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the aractic region anomaly year 2020\n",
    "da_plot_arctic = temp_da_arctic.sel(year=2020)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': ccrs.Robinson()})\n",
    "\n",
    "contour_obj =  plot_trend(da_plot_arctic, lats_Arctic, lons_Arctic, levels=np.arange(-5, 5.5, 0.5), extend='both', cmap='RdBu_r',\n",
    "                                    title=\"Arctic region SAT anomaly 2020\", ax=ax, show_xticks=True, show_yticks=True)\n",
    "\n",
    "# colorbar\n",
    "cbar = plt.colorbar(contour_obj, ax=ax, orientation='horizontal', pad=0.05, aspect=50)\n",
    "cbar.set_label('Temperature anomaly (°C)')\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_forced_da_arctic,lons_Arctic, lats_Arctic = data_process.selreg(\n",
    "        temp_forced_da, lat, lon, lat1=lat1, lat2=lat2, lon1=lon1, \n",
    "        lon2=lon2)\n",
    "\n",
    "temp_internal_da_arctic,lons_Arctic, lats_Arctic = data_process.selreg(\n",
    "        temp_internal_da, lat, lon, lat1=lat1, lat2=lat2, lon1=lon1, \n",
    "        lon2=lon2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_forced_da_arctic_mean = data_process.calc_weighted_mean(temp_forced_da_arctic)\n",
    "temp_internal_da_arctic_mean = data_process.calc_weighted_mean(temp_internal_da_arctic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the arctic region SAT anomalies\n",
    "temp_da_arctic_mean = data_process.calc_weighted_mean(temp_da_arctic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_da_arctic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out = './Figure4/data/'\n",
    "\n",
    "# temp_da_arctic_mean.to_netcdf(dir_out + '1850_2022_Raw_arctic_mean.nc')\n",
    "# temp_forced_da_arctic_mean.to_netcdf(dir_out + '1850_2022_Forced_arctic_mean.nc')\n",
    "# temp_internal_da_arctic_mean.to_netcdf(dir_out + '1850_2022_Internal_arctic_mean.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warming hole\n",
    "lat3 = 42\n",
    "lat4 = 60\n",
    "lon3 = -50\n",
    "lon4 = -10\n",
    "# select the region\n",
    "temp_da_NorthAtlantic = {}\n",
    "lons_NorthAtlantic = {}\n",
    "lats_NorthAtlantic = {}\n",
    "\n",
    "temp_da_NorthAtlantic,lons_NorthAtlantic, lats_NorthAtlantic = data_process.selreg(\n",
    "        temp_da, lat, lon, lat1=lat3, lat2=lat4, lon1=lon3, \n",
    "        lon2=lon4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extratropical South Pacific region\n",
    "lat1 = -60\n",
    "lat2 = -40\n",
    "lon1 = 220\n",
    "lon2 = 280\n",
    "# select the region\n",
    "temp_da_SP = {}\n",
    "lons_SP = {}\n",
    "lats_SP = {}\n",
    "\n",
    "for i in temp_da.keys():\n",
    "    temp_da_SP[i],lons_SP[i], lats_SP[i] = data_process.selreg(\n",
    "        temp_da[i], lat, lon, lat1=lat1, lat2=lat2, lon1=lon1, \n",
    "        lon2=lon2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trapezoid region\n",
    "# Southeast Pacific coordinates\n",
    "lat5 = -25\n",
    "lat6 = 0\n",
    "lon5 = -160\n",
    "lon6 = -80\n",
    "lon7 = -110\n",
    "\n",
    "# transform the temp_da to dataarray, with the third dimension as the time\n",
    "temp_da_array = xr.DataArray(list(temp_da.values()), \n",
    "                              dims=['time', 'lat', 'lon'], \n",
    "                              coords={'time': np.arange(1950, 2014, 1), 'lat': lat, 'lon': lon})\n",
    "\n",
    "da_plot = temp_da_array.sel(time=1993)\n",
    "\n",
    "levels = np.arange(-0.5, 0.55, 0.05)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = gridspec.GridSpec(1, 1, figure=fig, hspace=0.01, wspace=0.01)\n",
    "\n",
    "ax = fig.add_subplot(gs[0,0], projection=ccrs.Robinson(180))\n",
    "temp_annual_da_with_cyclic, lon_cyclic = cutil.add_cyclic_point(da_plot, coord=lon)\n",
    "# pvalue_annual_da_with_cyclic, _ = cutil.add_cyclic_point(pvalue_annual_da['40yr'], coord=lon)\n",
    "contour_obj = plot_trend(temp_annual_da_with_cyclic, lat, lon_cyclic, levels=levels,extend='both', cmap='twilight_shifted',\n",
    "            title=\" \", ax=ax, show_xticks=False, show_yticks=True)\n",
    "ax.set_title('Raw', fontsize=22, pad=10.0)\n",
    "\n",
    "plt.show()\n",
    "# %%\n",
    "# select the region with mask\n",
    "temp_da_array_sep = temp_da_array.sel(lat=slice(lat5, lat6), lon=slice(lon5, lon6))\n",
    "# %%\n",
    "plot_data = temp_da_array_sep.sel(time=1993)\n",
    "levels = np.arange(-0.5, 0.55, 0.05)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = gridspec.GridSpec(1, 1, figure=fig, hspace=0.01, wspace=0.01)\n",
    "\n",
    "ax = fig.add_subplot(gs[0,0], projection=ccrs.Robinson(180))\n",
    "# temp_annual_da_with_cyclic, lon_cyclic = cutil.add_cyclic_point(temp_da_array_sep, coord=lon)\n",
    "# pvalue_annual_da_with_cyclic, _ = cutil.add_cyclic_point(pvalue_annual_da['40yr'], coord=lon)\n",
    "contour_obj = plot_trend(plot_data, plot_data.lat, plot_data.lon, levels=levels,extend='both', cmap='twilight_shifted',\n",
    "            title=\" \", ax=ax, show_xticks=False, show_yticks=True)\n",
    "ax.set_title('Raw', fontsize=22, pad=10.0)\n",
    "\n",
    "plt.show()\n",
    "# %%\n",
    "import src.Polygon_region as poly\n",
    "# %%\n",
    "# define the polygon region \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import matplotlib.pyplot as pl\n",
    "    pl.close('all')\n",
    "\n",
    "    # Dummy data.\n",
    "    lats = temp_da_array_sep.lat.values\n",
    "    lons = temp_da_array_sep.lon.values\n",
    "    print(lats)\n",
    "    print(lons)\n",
    "    \n",
    "    data = np.arange(lats.size*lons.size).reshape((lats.size, lons.size))\n",
    "    \n",
    "    # Bounding box.\n",
    "    poly_x = np.array([-110, -160, -80, -80, -110])  # Longitude values\n",
    "    poly_y = np.array([-25, 0, 0, -25, -25])         # Latitude values\n",
    "    \n",
    "    # Generate mask for calculating statistics.\n",
    "    mask = np.zeros_like(data, dtype=bool)\n",
    "    poly.get_mask(mask, lons, lats, poly_x, poly_y)\n",
    "    \n",
    "    # Calculate statistics.\n",
    "    max_val = data[mask].max()\n",
    "    \n",
    "    # Plot data and mask.\n",
    "    pl.figure(figsize=(10,4))\n",
    "    pl.subplot(121)\n",
    "    pl.title('data')\n",
    "    pl.pcolormesh(lons, lats, data)\n",
    "    pl.plot(poly_x, poly_y)\n",
    "    pl.colorbar()\n",
    "    \n",
    "    pl.subplot(122)\n",
    "    pl.title('averaging mask, max_value={}'.format(max_val))\n",
    "    pl.pcolormesh(lons, lats, mask)\n",
    "    pl.plot(poly_x, poly_y)\n",
    "    pl.colorbar()\n",
    "    \n",
    "    pl.tight_layout()\n",
    "# %%\n",
    "# select the region with mask\n",
    "mask = mask[None,:,:]\n",
    "# %%\n",
    "temp_da_SoutheastPacific = temp_da_array_sep.where(mask)\n",
    "# %%\n",
    "# plot the region\n",
    "temp_da_SoutheastPacific.isel(time=43).plot()\n",
    "# %%\n",
    "temp_da_SoutheastPacific_mean = temp_da_SoutheastPacific.mean(dim=['lat', 'lon'], skipna=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segments definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "start_year = 1950\n",
    "end_year = 2022\n",
    "min_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(start_year, end_year + 1)\n",
    "\n",
    "# Prepare a dictionary to hold the trend DataArrays for each period\n",
    "temp_data_segments = {}\n",
    "\n",
    "for begin_year in range(start_year, end_year - min_length+2):\n",
    "    # Select the data from the start year to the last year\n",
    "    time_slice = temp_da_arctic_mean.sel(year=slice(begin_year, end_year))\n",
    "    \n",
    "    temp_data_segments[begin_year] = time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_forced_segments = {}\n",
    "temp_data_internal_segments = {}\n",
    "\n",
    "for begin_year in range(start_year, end_year - min_length+2):\n",
    "    # Select the data from the start year to the last year\n",
    "    time_slice = temp_forced_da_arctic_mean.sel(year=slice(begin_year, end_year))\n",
    "    \n",
    "    temp_data_forced_segments[begin_year] = time_slice\n",
    "\n",
    "for begin_year in range(start_year, end_year - min_length+2):\n",
    "    # Select the data from the start year to the last year\n",
    "    time_slice = temp_internal_da_arctic_mean.sel(year=slice(begin_year, end_year))\n",
    "    \n",
    "    temp_data_internal_segments[begin_year] = time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_data_segments.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the trend for each segment\n",
    "trends = {}\n",
    "\n",
    "for begin_year in temp_data_segments.keys():\n",
    "    temp_data = temp_data_segments[begin_year]\n",
    "    temp_data_forced = temp_data_forced_segments[begin_year]\n",
    "    temp_data_internal = temp_data_internal_segments[begin_year]\n",
    "    \n",
    "    # Calculate the trend for each segment\n",
    "    trends[begin_year] = {}\n",
    "    trends[begin_year]['raw'] = data_process.mk_test(temp_data,a=0.05)[0]*10.0\n",
    "    trends[begin_year]['forced'] = data_process.mk_test(temp_data_forced,a=0.05)[0]*10.0\n",
    "    trends[begin_year]['internal'] = data_process.mk_test(temp_data_internal,a=0.05)[0]*10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dictionary to dataframe\n",
    "trends_df = pd.DataFrame(trends).T\n",
    "trends_df\n",
    "\n",
    "# for interval, data in temp_annual_np.items():\n",
    "#     temp_annual_da[interval] = xr.DataArray(data, dims=[\"lat\", \"lon\"], coords={\"lat\": temp_data[interval].lat, \"lon\": temp_data[interval].lon})\n",
    "# for interval, data in pvalue_annual_np.items():\n",
    "#     pvalue_annual_da[interval] = xr.DataArray(data, dims=[\"lat\", \"lon\"], coords={\"lat\": temp_data[interval].lat, \"lon\": temp_data[interval].lon})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame to dataset\n",
    "trends_ds = trends_df.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the trend to the netcdf file\n",
    "trends_ds.to_netcdf(dir_out + 'Arctic_trend_variations.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirin = './Figure4/data/'\n",
    "arctic_unforced_lower = xr.open_dataset(f'{dirin}internal_arctic_trend_lower_percentile.nc')\n",
    "arctic_unforced_upper = xr.open_dataset(f'{dirin}internal_arctic_trend_upper_percentile.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_unforced_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_unforced_lower = arctic_unforced_lower.rename_vars({'__xarray_dataarray_variable__':'trend'})\n",
    "arctic_unforced_upper = arctic_unforced_upper.rename_vars({'__xarray_dataarray_variable__':'trend'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "# Set the font dictionaries (for plot title and axis titles)\n",
    "title_font = {'fontname': 'Arial', 'size': '20', 'color': 'black', 'weight': 'normal',\n",
    "                'verticalalignment': 'bottom'}  # Bottom vertical alignment for more space\n",
    "axis_font = {'fontname': 'Arial', 'size': '20'}\n",
    "\n",
    "# Create the plot\n",
    "fig = plt.figure(figsize=(25, 15))\n",
    "gs = gridspec.GridSpec(2, 2, wspace=0.25, hspace=0.7)\n",
    "\n",
    "ax1 = plt.subplot(gs[0, 0])\n",
    "ax2 = plt.subplot(gs[0, 1])\n",
    "ax3 = plt.subplot(gs[1, 0])\n",
    "ax4 = plt.subplot(gs[1, 1])\n",
    "\n",
    "# define rgb colors for the outlines\n",
    "# colors = [(32,120,180), #blue\n",
    "#           (106,61,154), #purple\n",
    "#           (173,23,88), #magenta\n",
    "#           (255,127,0), #orange\n",
    "#           (226,26,27),#red\n",
    "#           (49,160,45) #green\n",
    "#          ]\n",
    "# colors_set = [(r / 255, g / 255, b / 255) for r, g, b in colors]\n",
    "colors = ['#0F1023','#B11927', '#407BD0', '#B7D0EA']\n",
    "line_widths = [5.5, 5.5, 5.5, 5.5, 1.5, 1.5, 1.5]\n",
    "titles = ['Arctic(ARC)', 'Warming Hole(WH)', 'Southeast Pacific(SEP)', 'Southern Ocean Pacific sector(SOP)']\n",
    "linestyles = ['-', '-', '-.', ':']\n",
    "\n",
    "vars = ['raw', 'forced', 'internal']\n",
    "# We use a loop to simulate multiple lines for each category\n",
    "for i, var in enumerate(vars):\n",
    "    # Plot the forced trends for the EU region\n",
    "    sns.lineplot(x=np.arange(1950,2014), y=trends_ds[var].values, color=colors[i], linestyle=linestyles[i], linewidth=3.5, ax=ax1)\n",
    "\n",
    "ax1.fill_between(np.arange(1950,2014), arctic_unforced_lower.trend.values[::-1], arctic_unforced_upper.trend.values[::-1], color=colors[3])\n",
    "\n",
    "ax1.set_xlim([1945, 2015])\n",
    "ax1.set_ylim([-1.0, 1.0])\n",
    "ax1.set_xticks([1953, 1963, 1973, 1983, 1993, 2003, 2013])\n",
    "ax1.set_xticklabels(['1953', '1963', '1973', '1983', '1993', '2003', '2013'])\n",
    "ax1_upper = ax1.twiny()\n",
    "ax1_upper.invert_xaxis()\n",
    "ax1_upper.set_xlim([78,8])\n",
    "ax1_upper.set_xlabel('Length of trends', fontsize=28, labelpad=10)\n",
    "ax1_upper.set_xticks([70, 60, 50, 40, 30, 20, 10])\n",
    "ax1_upper.set_xticklabels(['70', '60', '50', '40', '30', '20', '10'])\n",
    "ax1.spines['top'].set_linewidth(2.5)\n",
    "ax1.spines['right'].set_linewidth(2.5)\n",
    "ax1.spines['bottom'].set_linewidth(2.5)\n",
    "ax1.spines['left'].set_linewidth(2.5)\n",
    "ax1_upper.tick_params(axis='x', labelsize=26)\n",
    "ax1_upper.tick_params(axis='x', which='major', length=12, width=2.5, direction='in')\n",
    "ax1.axhline(y=0, color='grey', linestyle='--', linewidth=2.5, alpha=0.75)\n",
    "ax1.set_ylabel('Trend value (°C/decade)', fontsize=30)\n",
    "ax1.set_xlabel('Start year of linear trend', fontsize=30)\n",
    "ax1.set_title(titles[0], loc='left',fontsize=32,pad=20)\n",
    "ax1.tick_params(axis='x', which='major', length=12, width=2.5, direction='in')\n",
    "ax1.tick_params(axis='y', which='major', length=12, width=2.5, direction='in')\n",
    "ax1.axvline(x=2013, color='#999A9E', linestyle='-', linewidth=2.5, alpha=0.75)\n",
    "ax1.axvline(x=1993, color='#999A9E', linestyle='-', linewidth=2.5, alpha=0.75)\n",
    "ax1.axvline(x=1979, color='#999A9E', linestyle='-', linewidth=2.5, alpha=0.75)\n",
    "ax1.axvline(x=1963, color='#999A9E', linestyle='-', linewidth=2.5, alpha=0.75)\n",
    "ax1.text(1979.1, -0.96, '1979-2022', fontsize=26, rotation=90, color='#999A9E')\n",
    "ax1.text(1940, 1.58, 'a', fontsize=42, ha='center', va='center', fontweight='bold')\n",
    "custom_lines = [Line2D([0], [0], color=colors[0], lw=3.5),\n",
    "                Line2D([0], [0], color=colors[1], lw=3.5),\n",
    "                Line2D([0], [0], color=colors[2], lw=3.5)]\n",
    "leg2 = ax1.legend(custom_lines, ['total', 'human forced', 'internal variability'], \n",
    "                  loc='lower left', fontsize=26)\n",
    "ax1.add_artist(leg2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Kernel",
   "language": "python",
   "name": "my-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
